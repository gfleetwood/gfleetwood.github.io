[
  {
    "objectID": "posts/3_local_dns_websites/index.html",
    "href": "posts/3_local_dns_websites/index.html",
    "title": "Building Local DNS Websites",
    "section": "",
    "text": "I use Google Chrome as my main browser, but I’ve been thinking of switching (or at least trying out) others. This possibility is hampered by Chrome lock-in powered by extensions and bookmarks, with the latter being the main issue.\nThe initial step involved a browser agnostic bookmark manager. I settled on buku which is cli based with an additional buku server to allow administration through a web interface. The next step was to permanently run buku server on a local port. Easy enough with systemd. Instead of bookmarking or typing 127.0.0.8000 (for example), I wanted to be able to type buku.me instead. That turned out to be much harder.\nAll these instructions pertain to Ubuntu 20.04.\nStep 1:\nInstall buku And buku server: pip3 install buku[server].\nStep 2:\nPermanently run buku server with system d.\nAdd this script as an executable to your bin folder. (Mine is called buku_server.) You’ll have to find out where buku server is installed with which bukuserver.\n# I'm using port 5555 but choose whichever port you want\n/home/gordon/miniconda3/bin/bukuserver run --host 127.0.0.1 --port 5555\n\nNext add this service file, buku_server.service, to /etc/systemd/system.\n[Unit]\nDescription=Buku Server\n\n[Service]\nUser=gordon\nWorkingDirectory=/home/gordon/.local/mybin\nExecStart=/bin/bash /home/gordon/.local/mybin/buku_server\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n\nStart and enable the service.\nsystemctl start buku_server.service\nsystemctl enable buku_server.service\n\nGo to 127.0.0.1:5555 to check that buku server is running.\nStep 3:\nThis was the draw the rest of the owl part for me. I finally understood the process due to this blog:\nhttps://www.interserver.net/tips/kb/local-domain-names-ubuntu/\nFirst you need to add a line to your /etc/hosts file: 127.0.0.1 buku.me. Then add this to a configuration file in /etc/apache2/sites-available (mine is 000-default.conf):\n# ServerName, ProxyPass, and ProxyPasReverse are the entries to change\n\n<VirtualHost *:80>\n  ServerAdmin test@test.com\n  ServerName buku.me\n  ProxyPass / <http://127.0.0.1:5555/>\n  ProxyPassReverse / <http://127.0.0.1:5555/>\n</VirtualHost>\n\nWith that I was able to go to buku.me in my browser to access the buku server.\nBonus:\nEven with this setup I still had to manually add urls to buku server. I wanted to have a shortcut, CTRL+B, that would automatically add a url. This solution actually adds whatever is on the clipboard to buku, so it’s on me to make sure it’s a url.\nIn Ubuntu I mapped this custom shortcut to CTRL+B: home/gordon/buku_add.py where buku_add.py is:\nimport pyperclip\nimport os\n\nos.system(\"buku -a {}\".format(pyperclip.paste()))\n\nbuku_add.py is a vanilla Python script instead of an executable because that didn’t work. I have no idea why."
  },
  {
    "objectID": "posts/6_truth_tables/index.html",
    "href": "posts/6_truth_tables/index.html",
    "title": "Propositional Logic In Python",
    "section": "",
    "text": "from itertools import product\nfrom pandas import DataFrame\n \nexp = lambda a, b, c, d, e: a and b or c and d and e\nexp2 = lambda a, b, c, d, e: a and (b or c) and d and e\n \ndef exp3(a, b, c, d, e): \n \n  result = a and b or c and d and e\n  truth_table = {\"a\": a, \"b\": b, \"c\": c, \"d\": d, \"e\": e, \"a & b | c & d & e\": result}\n \n  return(truth_table)\n \narr = [False, True]\ncartesian_product = list(product(arr, arr, arr, arr, arr))\n \n#for a,b in zip(list(map(lambda x: exp(*x), cartesian_product)), list(map(lambda x: exp2(*x), cartesian_product))):\n#  print(a == b)\n \ntruth_table = list(map(lambda x: exp3(*x), cartesian_product))\ntruth_table_df = DataFrame(truth_table)\n \ntruth_table_df"
  },
  {
    "objectID": "posts/1_welcome/index.html",
    "href": "posts/1_welcome/index.html",
    "title": "Your Keyboard As A Mouse",
    "section": "",
    "text": "First I tried synthesizing this keyboard enhancement drug in Python with pyinput and pyautogui. That worked in testing but I couldn’t get it to work with systemd as a permanent application. Someone helpfully pointed out that there were some lower level shenanigans going on, but I wasn’t sure how to proceed so I abandoned this work for a while.\nI forget the catalyst for its revival, but somehow I came across the exact architecture I needed to use: 1 2. xbindkeys and xte became the keys to my success.\nsudo apt update\nsudo apt-get install xbindkeys -y\nsudo apt-get install xautomation -y\ntouch ~/.xbindkeysrc\nxbindkeys --key # find name of key\nkillall -s1 xbindkeys # make xbindkeys reload config\nxbindkeys # start xbindkeys daemon\nxbindkeys -f ~/.xbindkeysrc\nAnd inside the .xbindkeysrc config file:\n# Keyboard as Mouse\n\n# move mouse up (with alt+w)\n\"xte 'mousermove 0 -10'\"\n   alt+w\n\n# move mouse down\n\"xte 'mousermove 0 10'\"\n   alt+s\n\n# move mouse left\n\"xte 'mousermove -10 0'\"\n   alt+a\n\n# move mouse right\n\"xte 'mousermove 10 0'\"\n   alt+d\n\n# left click\n\"sleep 1 && xte 'mouseclick 1'\"\n   alt+q\n\n# right click\n\"sleep 1 && xte 'mouseclick 3'\"\n   alt+e"
  },
  {
    "objectID": "posts/2_post-with-code/index.html",
    "href": "posts/2_post-with-code/index.html",
    "title": "Automatic Audio Books",
    "section": "",
    "text": "The book I choose was Carroll Quigley’s “The Evolution Of Civilizations”. I’m at a point where I am militantly electronic with my reading, so the pdf link from Twitter was perfect. Skimming the book I got the sense that I’d prefer to listen rather than read it - a bifurcation that I recently adopted after ignoring audiobooks for years. No audiobook on Amazon’s left me only one option. (Well there was the possibility of using an end to end implementation like Speechify but where would be the fun in that?)\nThree days from idea to completion is the small, visible part of an enormous glacier. Beneath the surface lies hours of previous research into pdf extraction and text to speech (also speech to text) programs. The pipeline and its implementation almost immediately existed as one entity in my mind. Here was my process:\n\nUse pdf extraction to get the text\n\nlibrary(pdftools)\n\ntext_extracted <- pdf_text(\"auto-audio-book/CarrollQuigley-TheEvolutionOfCivilizations-AnIntroductionToHistoricalAnalysis1979.pdf\")\n\ntext_concatenated <- paste(text_extracted, collapse = \" \")\ncon <- file(\"evol_of_civilizations.txt\")\nwriteLines(text_concatenated, con)\nclose(con)\n\nCheck.\n\nClean the text\n\nSo I lied about the automatically part. I still had to go into the document and delete footers, references, the table of contents, etc, and I left stuff in there because it was too tedious to go through a 400+ page book to get every single one. Much easier to ignore them while listening. Alternatively this could be done after the text to speech conversion using a service like descript.\n\nUse text to speech to create the audio\n\nThis turned out to be more of a hassle than I thought it would be. First I went through Google’s convoluted process to get the Text To Speech API working. Then my attempt at making a single mp3 was thwarted by the API’s limits. Chunking the file and adding in a delay (*What felt like two hours later*) left me with 180 separate mp3s. (In retrospect I should have used the multiprocess module to speed it up.)\nfrom google.cloud import texttospeech\nimport time\n\ndef tts_book(ind, text_chunk):\n    # Instantiates a client\n    client = texttospeech.TextToSpeechClient()\n\n    # Set the text input to be synthesized\n    synthesis_input = texttospeech.types.SynthesisInput(text = text_chunk)\n\n    # Build the voice request, select the language code (\"en-US\") and the ssml\n    # voice gender (\"neutral\")\n    voice = texttospeech.types.VoiceSelectionParams(\n        language_code = 'en-US-Wavenet-B',\n        ssml_gender = texttospeech.enums.SsmlVoiceGender.NEUTRAL\n        )\n\n    # Select the type of audio file you want returned\n    audio_config = texttospeech.types.AudioConfig(\n        audio_encoding = texttospeech.enums.AudioEncoding.MP3\n        )\n\n    # Perform the text-to-speech request on the text input with the selected\n    # voice parameters and audio file type\n    response = client.synthesize_speech(synthesis_input, voice, audio_config)\n\n    # The response's audio_content is binary.\n    with open('output_{}.mp3'.format(ind), 'wb') as out:\n        # Write the response to the output file.\n        out.write(response.audio_content)\n        print('Audio content written to file \"output_{}.mp3\"'.format(ind))\n\n    return(1)\n\nwith open(\"auto-audio-book/evol-of-civilizations-cleaned.txt\", \"r\") as f:\n    evol_civ = f.read().replace(\"\\\\n\", \" \")\n\nchunks = []\ntemp = evol_civ\n\nwhile len(temp) != 0:\n\n    chunks.append(temp[:4000])\n    temp = temp[4000:]\n\nfor ind, chunk in enumerate(chunks):\n    _ = tts_book(ind, chunk)\n    time.sleep(10)\n\nIt was a pretty small wrench though. I knew ffmpeg was the solution I needed. The tricky bit was in getting it to work. After some Googling I assembled the parts:\n# Get all the mp3 names and write them to a text file.\nls | grep \"output\" > mp3-files.txt\n\n# Prepend the word \"file\" to each line of said text file.\nawk '{print \"file \" $0}' mp3-files.txt > mp3-files.txt\n\n# Bring in the heavy guns to produce the combined file\nffmpeg -f concat -safe 0 -i mp3-files.txt -c copy output-final.mp3\n\nSuccess!"
  },
  {
    "objectID": "posts/5_colored_equations/index.html",
    "href": "posts/5_colored_equations/index.html",
    "title": "Colored Equations",
    "section": "",
    "text": "https://github.com/gfleetwood/gfleetwood.github.io/blob/master/index.Rmd\nIn particular pay attention to the LaTeX packages in the yaml header (header-includes:).\n\\(\\color{blue}{y} = \\color{green}{m}\\color{red}{x} + \\color{orange}{b}\\)\nFor every one unit change in the independent variable there is a change in the dependent variable plus some offset/bias to represent the value of the dependent variable when the independent variable is zero.\nFor example, consider a mock linear relationship between a person’s weight in pounds and their height in inches.\n\\(\\color{blue}{Weight} = \\color{green}{2}*\\color{red}{Height} + \\color{orange}{12}\\)\nThis says that it is expected that a person’s weight will increase by 2 pounds for every additional inch in their height. If a person’s height were 0 inches, then their weight would be 12 pounds.\nFrom DataCamp’s Bayesian course\n\\(P(\\color{orange}{\\theta}|\\color{purple}{D}) = \\frac{\\color{green}{P(D|\\theta)}\\times \\color{blue}{P(\\theta})}{\\color{red}{\\Sigma{P(D|\\theta)} \\times P(\\theta)}}\\)\n\nThe probability of different parameter values given some data is the likelihood (The relative probability of the data given different parameter values) multiplied by the prior (The probability of different parameters before seeing the data) divided by the total sum of the likelihood weighted by the prior."
  },
  {
    "objectID": "posts/4_automating_wordle/index.html",
    "href": "posts/4_automating_wordle/index.html",
    "title": "Automating Wordle",
    "section": "",
    "text": "https://typon.github.io/wordle.html\nMy armchair fascination with formal methods in computer science often crossed paths with SAT solvers, but I never really gave them more than a cursory look for the depth involved. This seemed like a good opportunity to dive a bit deeper.\nBut that scope only really involved reading the blog and maybe running some lines of code. I need a deeper hook. One eventually came to mind. All the programmatic solutions were only really partially automated. A user would run code, see the wordle feedback, and then make adjustments as needed. I wanted to eliminate the need for adjustments. Everything would be automated.\nHow to begin. Well, some light RPA was key. I’m not a fan since I think the field is a walking anti-pattern, but it does have its uses. The first snippet of code opened a link to a Wordle clone without the once a day playing limit (https://hellowordl.net/), and used Python’s pyautogui to enter letters and take a screenshot. Some fiddling around with cropping produced this:\nNot bad. Next was the process of detecting letter and colors. Each square is about 55 pixels length and width, so a simple double for loop sufficed. Some googling helped me write this function to get the dominant color in a square:\ndef get_dominant_color(letter_square):\n\n  img = Image.fromarray(letter_square)\n  dom_color = sorted(img.getcolors(2 ** 24), reverse = True)[0][1]\n\n  return(dom_color)\nWhich I saved as a variable:\nCOLORS = [\n(\"yellow\", (228, 218, 0)), \n(\"gray\", (162, 162, 162)), \n(\"green\", (63, 186, 119))\n]\nOf course trying to match colors exactly is just calling for frustration. I used a distance metric instead.\nNext I wanted to use OCR to identify the letters. This easily took up most of my time. Through trial and error I came up with a computer vision pipeline that cleaned up the image above so much that a blind man could see which letters the image contained. Unfortunately neither pytesseract nor the Google Cloud API could. Despair began to set in.\nI’m sure you’re now confused. “Why OCR? Aren’t the letters already known since you’re entering the words?” I eventually came to realization as well, and jettisoned (read saved for reference) all that computer vision code.\nI went some way towards writing my own non-Z3 solver before remember my initial goal. Instead I copied over the relevant Z3 code from https://typon.github.io/wordle.html and worked to integrate it into my framework.\nMy big addition was the logic of how and when to add constraints to the solver. There are seven, two of which are static:\n\nOnly 26 letters (0-25)\nOnly five letter words (sourced from Linux’s dictionary)\n\nThe other five are dynamic. In parentheses are the color/s they pertain to:\n\nWord contains letter (green, yellow)\nWrong position in word for letter (yellow)\nRight position in word for letter (green)\nWord doesn’t contain letter (gray)\nWord contains only one instance of the letter (green, yellow)\n\nThe last one was the stickler. When the code is being manually updated it’s easy to enough to wield, but in a fully automated setup it was just breaking. Consider a word like flood. If I guessed flodd the first d would be gray and the other green. With z3 this would adds constraints that d is both in and not in the word. You immediately see why this is a problem. I need to check if a letter that should be considered was already labeled as not being in the word and then remove that constraint.\nThis, apparently, is not trivial in z3. The closest method is solver.remove() which removes all constraints from the solver. Not ideal. Armed with my accumulated z3 resources I finally delved deep into its workings, and arrived at an answer. I added this snippet of code to the cases where the letter was green or yellow:\ncheck_if_grey_before = f\"letter_{str(letter_info[2])} != {letter_to_index_map[letter_info[0]]}\"\nconstraints = solver.assertions()\nnew_constraints = [\nconstraint \nfor constraint in constraints \nif constraint.__repr__() != check_if_grey_before\n]\n\nif len(constraints) != len(new_constraints): \n  solver.reset()\n  solver.add(new_constraints)\nIn a nutshell it checks if the current constraints say the letter wasn’t in the word. If yes, then it filters out that constraint, resets the solver, and then adds back the constraints. I also added logic to the gray condition to skip saying a letter wasn’t in the word if it was already added as being in it.\nMy solution worked well sometimes, but the solver still broke down. Obviously I attributed this to some wonky logic in updating the solver, so I added logging code to see what constraints are being used on each turn. Looking at the logic led me to the true culprit. Turns out my color detection was not as ironclad as I thought.\nHere’s the full code: gfleetwood/auto-wordle"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Oct 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]